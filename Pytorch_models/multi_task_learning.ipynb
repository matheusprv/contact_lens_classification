{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(train_test):\n",
    "  lines = []\n",
    "  with open(f\"lens/CogentAnnotation{train_test}.csv\", \"r\") as file:\n",
    "      \n",
    "    csvreader = csv.reader(file)\n",
    "\n",
    "    for row in csvreader:\n",
    "        lines.append(np.asarray(row))\n",
    "\n",
    "  lines.pop(0) #Removing the header of the file\n",
    "  lines = np.array(lines).T #Transposing to recover the data easier\n",
    "\n",
    "  return lines\n",
    "\n",
    "def label_classifier(lens_labels, gender_labels, black_withe_labels):\n",
    "    lens_labels_types = {\"Colored\": 0, \"Normal\": 1, \"Transparent\": 2}\n",
    "    gender_types = {\"Male\": 0, \"Female\": 1}\n",
    "    black_withe_types = {\"No\": 0, \"Yes\": 1}\n",
    "\n",
    "    num_labels = len(lens_labels)\n",
    "    for i in range(num_labels):\n",
    "        lens_labels[i] = lens_labels_types[lens_labels[i]]\n",
    "        gender_labels[i] = gender_types[gender_labels[i]]\n",
    "        black_withe_labels[i] = black_withe_types[black_withe_labels[i]]\n",
    "\n",
    "    lens_labels = lens_labels.astype(np.int32)\n",
    "    gender_labels = gender_labels.astype(np.int8)\n",
    "    black_withe_labels = black_withe_labels.astype(np.int8)\n",
    "\n",
    "    return lens_labels, gender_labels, black_withe_labels\n",
    "\n",
    "def normalize_array(arr):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    return (arr - mean[:, None, None]) / std[:, None, None]\n",
    "\n",
    "def read_images(images_path):\n",
    "    images = []\n",
    "    for img_name in images_path:\n",
    "        img = Image.open(\"lens/\" + img_name + \".bmp\")\n",
    "        img = img.resize((300,300))\n",
    "        img = np.asarray(img).astype(np.float64) / 255.0\n",
    "        img = np.stack((img,)*3, axis=0)\n",
    "        images.append(normalize_array(img))\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "def read_data(train_test, number_of_samples):\n",
    "\n",
    "    #Picking random samples from the dataset\n",
    "    number_of_samples = 1750 if number_of_samples > 1750 else number_of_samples\n",
    "    samples_index = (random.sample(range(0, 1749 + 1), number_of_samples))\n",
    "\n",
    "    #Reading from the csv all the information needed\n",
    "    csv_info = read_csv(train_test)\n",
    "    images_path = np.array([])\n",
    "    lens_labels = np.array([])\n",
    "    gender_labels = np.array([])\n",
    "    black_withe_labels = np.array([])\n",
    "    pupilX = np.array([])\n",
    "    pupilY = np.array([])\n",
    "    pupilR = np.array([])\n",
    "    irisX = np.array([])\n",
    "    irisY = np.array([])\n",
    "    irisR = np.array([])\n",
    "\n",
    "    for index in samples_index:\n",
    "        images_path = np.append(images_path, csv_info[0][index])\n",
    "        lens_labels = np.append(lens_labels, csv_info[1][index])\n",
    "        gender_labels = np.append(gender_labels, csv_info[4][index])\n",
    "        black_withe_labels = np.append(black_withe_labels, csv_info[5][index])\n",
    "        pupilX = np.append(pupilX, csv_info[6][index])\n",
    "        pupilY = np.append(pupilY, csv_info[7][index])\n",
    "        pupilR = np.append(pupilR, csv_info[8][index])\n",
    "        irisX = np.append(irisX, csv_info[9][index])\n",
    "        irisY = np.append(irisY, csv_info[10][index])\n",
    "        irisR = np.append(irisR, csv_info[11][index])\n",
    "\n",
    "\n",
    "    pupilX = pupilX.astype(np.float32)\n",
    "    pupilY = pupilY.astype(np.float32)\n",
    "    irisX = irisX.astype(np.float32)\n",
    "    irisY = irisY.astype(np.float32)\n",
    "    pupilR = pupilR.astype(np.float32)\n",
    "    irisR = irisR.astype(np.float32)\n",
    "\n",
    "    #Processing the labels and reading the images\n",
    "    lens_labels, gender_labels, black_withe_labels = label_classifier(lens_labels, gender_labels, black_withe_labels)\n",
    "    images = read_images(images_path)\n",
    "\n",
    "    return images, lens_labels, gender_labels, black_withe_labels, pupilX, pupilY, pupilR, irisX, irisY, irisR\n",
    "\n",
    "images_train, lens_labels_train, gender_labels_train, black_withe_labels_train, pupilX_labels_train, pupilY_labels_train, pupilR_labels_train, irisX_labels_train, irisY_labels_train, irisR_labels_train = read_data(\"train\", 400)\n",
    "images_test, lens_labels_test, gender_labels_test, black_withe_labels_test, pupilX_labels_test, pupilY_labels_test, pupilR_labels_test, irisX_labels_test, irisY_labels_test, irisR_labels_test = read_data(\"test\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting data to tensor\n",
    "train_x = torch.from_numpy(images_train).to(torch.float32)\n",
    "train_lens_label = torch.from_numpy(lens_labels_train).to(torch.float32)\n",
    "train_gender_label = torch.from_numpy(gender_labels_train).to(torch.float32)\n",
    "train_black_white_label = torch.from_numpy(black_withe_labels_train).to(torch.float32)\n",
    "train_pupilX_label = torch.from_numpy(pupilX_labels_train).to(torch.float32)\n",
    "train_pupilY_label = torch.from_numpy(pupilY_labels_train).to(torch.float32)\n",
    "train_irisX__label = torch.from_numpy(irisX_labels_train).to(torch.float32)\n",
    "train_irisY__label = torch.from_numpy(irisY_labels_train).to(torch.float32)\n",
    "train_pupilR_label = torch.from_numpy(pupilR_labels_train).to(torch.float32)\n",
    "train_irisR__label = torch.from_numpy(irisR_labels_train).to(torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "test_x = torch.from_numpy(images_test).to(torch.float32)\n",
    "test_lens_label = torch.from_numpy(lens_labels_test).to(torch.float32)\n",
    "test_gender_label = torch.from_numpy(gender_labels_test).to(torch.float32)\n",
    "test_black_white_label = torch.from_numpy(black_withe_labels_test).to(torch.float32)\n",
    "test_pupilX_label = torch.from_numpy(pupilX_labels_test).to(torch.float32)\n",
    "test_pupilY_label = torch.from_numpy(pupilY_labels_test).to(torch.float32)\n",
    "test_irisX__label = torch.from_numpy(irisX_labels_test).to(torch.float32)\n",
    "test_irisY__label = torch.from_numpy(irisY_labels_test).to(torch.float32)\n",
    "test_pupilR_label = torch.from_numpy(pupilR_labels_test).to(torch.float32)\n",
    "test_irisR__label = torch.from_numpy(irisR_labels_test).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(train_x, train_lens_label, train_gender_label, train_black_white_label, train_pupilX_label, train_pupilY_label, train_pupilR_label, train_irisX__label, train_irisY__label, train_irisR__label)\n",
    "test = TensorDataset(test_x, test_lens_label, test_gender_label, test_black_white_label, test_pupilX_label, test_pupilY_label, test_pupilR_label, test_irisX__label, test_irisY__label, test_irisR__label)\n",
    "\n",
    "train_loaded = DataLoader(train, batch_size=8, shuffle=True)\n",
    "test_loaded = DataLoader(test, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def __init__(self, beta=1.0):\n",
    "        super(Swish, self).__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(self.beta * x)\n",
    "\n",
    "class lensModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(lensModel, self).__init__()\n",
    "\n",
    "        self.weights = torchvision.models.EfficientNet_B3_Weights.DEFAULT\n",
    "        self.efficientNetB3 = torchvision.models.efficientnet_b3(weights= self.weights)\n",
    "        self.efficientNetB3._avg_pooling = nn.Identity()\n",
    "        \n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.Linear(1000, 1536),\n",
    "            Swish(),\n",
    "\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(1536, 512),\n",
    "\n",
    "\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.lens_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(512, 256),\n",
    "\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=0.17),\n",
    "            nn.Linear(256, 3),\n",
    "            nn.Softmax(dim = 1)\n",
    "        )\n",
    "\n",
    "        self.gender_layer = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            Swish(),\n",
    "            nn.Linear(256, 1),  \n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "\n",
    "        self.black_white_layer = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            Swish(),\n",
    "\n",
    "            nn.Linear(256, 1),  \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.pupilX_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            Swish(),\n",
    "\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            Swish(),\n",
    "            \n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "        self.pupilY_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            Swish(),\n",
    "\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            Swish(),\n",
    "            \n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "        self.pupilR_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "        self.irisX_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            Swish(),\n",
    "\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            Swish(),\n",
    "            \n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "        self.irisY_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            Swish(),\n",
    "\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            Swish(),\n",
    "            \n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "        self.irisR_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.efficientNetB3(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Check if the batch size is 1, if so, bypass the BatchNormalization layer\n",
    "        if x.size(0) == 1:\n",
    "            x = self.shared_layers[1:](x)  # Skips the BatchNormalization layer\n",
    "        else:\n",
    "            x = self.shared_layers(x)\n",
    "\n",
    "        lens = self.lens_layer(x)\n",
    "        gender = self.gender_layer(x)\n",
    "        black_white = self.black_white_layer(x)\n",
    "        pupilX = self.pupilX_layer(x)\n",
    "        pupilY = self.pupilY_layer(x)\n",
    "        pupilR = self.pupilR_layer(x)\n",
    "        irisX = self.irisX_layer(x)\n",
    "        irisY = self.irisY_layer(x)\n",
    "        irisR = self.irisR_layer(x)\n",
    "        \n",
    "        return lens, gender, black_white, pupilX, pupilY, pupilR, irisX, irisY, irisR\n",
    "    \n",
    "model = lensModel()\n",
    "model.to(device)\n",
    "\n",
    "optimizer_lens  = torch.optim.SGD(model.lens_layer.parameters(), lr=0.0018)\n",
    "optimizer_gender  = torch.optim.Adam(model.gender_layer.parameters(), lr= 0.01)\n",
    "optimizer_black_white = torch.optim.Adam(model.black_white_layer.parameters(), lr= 0.01)\n",
    "optimizer_pupilX = torch.optim.Adam(model.pupilX_layer.parameters(), lr=0.001)\n",
    "optimizer_pupilY = torch.optim.Adam(model.pupilY_layer.parameters(), lr=0.001)\n",
    "optimizer_pupilR = torch.optim.Adam(model.pupilR_layer.parameters(), lr=0.001)\n",
    "optimizer_irisX = torch.optim.Adam(model.irisX_layer.parameters(), lr=0.001)\n",
    "optimizer_irisY = torch.optim.Adam(model.irisY_layer.parameters(), lr=0.001)\n",
    "optimizer_irisR = torch.optim.Adam(model.irisR_layer.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "criterion_lens = nn.CrossEntropyLoss()\n",
    "criterion_gender = nn.BCELoss()\n",
    "criterion_black_white = nn.BCELoss()\n",
    "criterion_pupilX = nn.BCELoss()\n",
    "criterion_pupilY = nn.BCELoss()\n",
    "criterion_pupilR = nn.BCELoss()\n",
    "criterion_irisX = nn.BCELoss()\n",
    "criterion_irisY = nn.BCELoss()\n",
    "criterion_irisR = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Batch [20/50] | \n",
      "\tLoss Lens: 19.69 | Loss Gender: 0.63 | Loss B/W: 0.20 | loss_pupilX: 32345.00 | loss_pupilY: 18306.88 | loss_irisX: 32325.00 | loss_irisY: 19710.62 | loss_pupilR: 4024.38 | loss_irisR: 12309.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Batch [40/50] | \n",
      "\tLoss Lens: 19.57 | Loss Gender: 0.62 | Loss B/W: 0.20 | loss_pupilX: 32041.88 | loss_pupilY: 18145.94 | loss_irisX: 32058.12 | loss_irisY: 19542.19 | loss_pupilR: 3996.25 | loss_irisR: 12154.69\n"
     ]
    }
   ],
   "source": [
    "def getOutputs(model, inputs):\n",
    "    lens_outputs, gender_outputs, black_white_outputs, pupilX_outputs, pupilY_outputs, pupilR_outputs, irisX_outputs, irisY_outputs, irisR_outputs = model(inputs)\n",
    "    _, lens_outputs = torch.max(lens_outputs.data, 1)\n",
    "    lens_outputs = lens_outputs.to(torch.float32)\n",
    "\n",
    "    gender_outputs = gender_outputs.view(-1)  # transforming from shape [batch_size, 1] to [batch_size]\n",
    "    black_white_outputs = black_white_outputs.view(-1)  # transforming from shape [batch_size, 1] to [batch_size]\n",
    "\n",
    "    _, pupilX_outputs = torch.max(pupilX_outputs.data, 1)\n",
    "    pupilX_outputs = pupilX_outputs.to(torch.float32)\n",
    "\n",
    "    _, pupilY_outputs = torch.max(pupilY_outputs.data, 1)\n",
    "    pupilY_outputs = pupilY_outputs.to(torch.float32)\n",
    "\n",
    "    _, irisX_outputs = torch.max(irisX_outputs.data, 1)\n",
    "    irisX_outputs = irisX_outputs.to(torch.float32)\n",
    "\n",
    "    _, irisY_outputs = torch.max(irisY_outputs.data, 1)\n",
    "    irisY_outputs = irisY_outputs.to(torch.float32)\n",
    "\n",
    "    _, pupilR_outputs = torch.max(pupilR_outputs.data, 1)\n",
    "    pupilR_outputs = pupilR_outputs.to(torch.float32)\n",
    "\n",
    "    _, irisR_outputs = torch.max(irisR_outputs.data, 1)\n",
    "    irisR_outputs = irisR_outputs.to(torch.float32)\n",
    "\n",
    "    return lens_outputs, gender_outputs, black_white_outputs, pupilX_outputs, pupilY_outputs, pupilR_outputs, irisX_outputs, irisY_outputs, irisR_outputs\n",
    "\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss_lens = total_loss_gender = total_loss_black_white = total_loss_coordinates = total_loss_radius = total_loss_pupilX = total_loss_pupilY = total_loss_irisX = total_loss_irisY = total_loss_pupilR = total_loss_irisR = 0.0\n",
    "    correct_lens = correct_gender = correct_black_white = correct_coordinates = correct_radius = correct_pupilX = correct_pupilY = correct_irisX = correct_irisY = correct_pupilR = correct_irisR = 0\n",
    "\n",
    "    for batch_idx, (images, lens_label, gender_label, black_white_label, pupilX_label, pupilY_label, pupilR_label, irisX_label, irisY_label, irisR_label) in enumerate(train_loaded):\n",
    "        #loading data to device\n",
    "        images = images.to(device)\n",
    "        lens_label = lens_label.to(device)\n",
    "        gender_label = gender_label.to(device)\n",
    "        black_white_label = black_white_label.to(device)\n",
    "        pupilX_label = pupilX_label.to(device)\n",
    "        pupilY_label = pupilY_label.to(device)\n",
    "        irisX_label = irisX_label.to(device)\n",
    "        irisY_label = irisY_label.to(device)\n",
    "        pupilR_label = pupilR_label.to(device)\n",
    "        irisR_label = irisR_label.to(device)\n",
    "\n",
    "\n",
    "        optimizer_lens.zero_grad()\n",
    "        optimizer_gender.zero_grad()\n",
    "        optimizer_black_white.zero_grad()\n",
    "        optimizer_pupilX.zero_grad()\n",
    "        optimizer_pupilY.zero_grad()\n",
    "        optimizer_irisX.zero_grad()\n",
    "        optimizer_irisY.zero_grad()\n",
    "        optimizer_pupilR.zero_grad()\n",
    "        optimizer_irisR.zero_grad()\n",
    "\n",
    "        #Receiving the model output\n",
    "        lens_output, gender_output, black_white_output, pupilX_output, pupilY_output, pupilR_outputs, irisX_output, irisY_output, irisR_output = getOutputs(model=model, inputs=images)\n",
    "\n",
    "        #Calculating the loss\n",
    "        loss_lens = criterion_lens(lens_output, lens_label.float())\n",
    "        loss_gender = criterion_gender(gender_output, gender_label)\n",
    "        loss_black_white = criterion_black_white(black_white_output, black_white_label)\n",
    "\n",
    "        loss_pupilX = criterion_pupilX(pupilX_output, pupilX_label)\n",
    "        loss_pupilY = criterion_pupilY(pupilY_output, pupilY_label)\n",
    "        loss_irisX = criterion_irisX(irisX_output, irisX_label)\n",
    "        loss_irisY = criterion_irisY(irisY_output, irisY_label)\n",
    "        loss_coordinates = loss_pupilX + loss_pupilY + loss_irisX + loss_irisY\n",
    "\n",
    "        loss_pupilR = criterion_pupilR(pupilR_outputs, pupilR_label)\n",
    "        loss_irisR = criterion_irisR(irisR_output, irisR_label)\n",
    "        loss_radius = loss_pupilR + loss_irisR\n",
    "\n",
    "        total_loss_lens += loss_lens.item()\n",
    "        total_loss_gender += loss_gender.item()\n",
    "        total_loss_black_white += loss_black_white.item()\n",
    "        total_loss_coordinates += loss_coordinates.item()\n",
    "        total_loss_radius += loss_radius.item()\n",
    "\n",
    "        total_loss_pupilX += loss_pupilX.item()\n",
    "        total_loss_pupilY += loss_pupilY.item()\n",
    "        total_loss_irisX += loss_irisX.item()\n",
    "        total_loss_irisY += loss_irisY.item()\n",
    "        total_loss_pupilR += loss_pupilR.item()\n",
    "        total_loss_irisR += loss_irisR.item()\n",
    "\n",
    "        loss = loss_lens + loss_gender + loss_black_white + loss_coordinates + loss_radius\n",
    "\n",
    "        #backprop\n",
    "        loss.backward()\n",
    "\n",
    "        #optimizing\n",
    "        optimizer_lens.step()\n",
    "        optimizer_gender.step()\n",
    "        optimizer_black_white.step()\n",
    "        optimizer_pupilX.step()\n",
    "        optimizer_pupilY.step()\n",
    "        optimizer_irisX.step()\n",
    "        optimizer_irisY.step()\n",
    "        optimizer_pupilR.step()\n",
    "        optimizer_irisR.step()\n",
    "\n",
    "        batches_done = epoch * len(train_loaded) + batch_idx\n",
    "        batches_left = num_epochs * len(train_loaded) - batches_done\n",
    "\n",
    "        if (batch_idx + 1) % 20 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}] | Batch [{batch_idx + 1}/{len(train_loaded)}] | \\n\\t\"\n",
    "                    f\"Loss Lens: {total_loss_lens / (batch_idx + 1):.2f} | \"\n",
    "                    f\"Loss Gender: {total_loss_gender / (batch_idx + 1):.2f} | \"\n",
    "                    f\"Loss B/W: {total_loss_black_white / (batch_idx + 1):.2f} | \"\n",
    "                    f\"loss_pupilX: {total_loss_pupilX/(batch_idx+1):.2f} | \"\n",
    "                    f\"loss_pupilY: {total_loss_pupilY/(batch_idx+1):.2f} | \"\n",
    "                    f\"loss_irisX: {total_loss_irisX/(batch_idx+1):.2f} | \"\n",
    "                    f\"loss_irisY: {total_loss_irisY/(batch_idx+1):.2f} | \"\n",
    "                    f\"loss_pupilR: {total_loss_pupilR/(batch_idx+1):.2f} | \"\n",
    "                    f\"loss_irisR: {total_loss_irisR/(batch_idx+1):.2f}\")\n",
    "\n",
    "        #Validating the data\n",
    "        correct_lens += torch.sum(lens_output == lens_label).item()\n",
    "        correct_gender += torch.sum(gender_output == gender_label).item()\n",
    "        correct_black_white += torch.sum(black_white_output == black_white_label).item()\n",
    "        correct_pupilX += torch.sum(pupilX_output == pupilX_label).item()\n",
    "        correct_pupilY += torch.sum(pupilY_output == pupilY_label).item()\n",
    "        correct_pupilR += torch.sum(pupilR_outputs == pupilR_label).item()\n",
    "        correct_irisX += torch.sum(irisX_output == irisX_label).item()\n",
    "        correct_irisY += torch.sum(irisY_output == irisY_label).item()\n",
    "        correct_irisR += torch.sum(irisR_output == irisR_label).item()\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch + 1}/{num_epochs}] | Loss Lens: {total_loss_lens / len(train_loaded):.2f} | \"\n",
    "            f\"Loss Gender: {total_loss_gender / len(train_loaded):.2f} | \"\n",
    "            f\"Loss B/W: {total_loss_black_white / len(train_loaded):.2f} | \"\n",
    "            f\"loss_pupilY: {total_loss_pupilY/(len(train_loaded)):.2f} | \"\n",
    "            f\"loss_irisX: {total_loss_irisX/(len(train_loaded)):.2f} | \"\n",
    "            f\"loss_irisY: {total_loss_irisY/(len(train_loaded)):.2f} | \"\n",
    "            f\"loss_pupilR: {total_loss_pupilR/(len(train_loaded)):.2f} | \"\n",
    "            f\"loss_irisR: {total_loss_irisR/(len(train_loaded)):.2f}\")\n",
    "\n",
    "    print(f\"Gender: {correct_lens * 100 /(len(train_loaded))} |\"\n",
    "          f\"B/W: {correct_gender * 100 /(len(train_loaded))} |\"\n",
    "          f\"B/W: {correct_black_white * 100 /(len(train_loaded))} |\")\n",
    "\n",
    "\n",
    "    print(\n",
    "        f\"lens: {correct_lens * 100 / (len(train_loaded))} | \"\n",
    "        f\"gender: {correct_gender * 100 / (len(train_loaded))} | \"\n",
    "        f\"black_white: {correct_black_white * 100 / (len(train_loaded))} | \"\n",
    "        f\"pupilX: {correct_pupilX * 100 / (len(train_loaded))} | \"\n",
    "        f\"pupilY: {correct_pupilY * 100 / (len(train_loaded))} | \"\n",
    "        f\"pupilR: {correct_pupilR * 100 / (len(train_loaded))} | \"\n",
    "        f\"irisX: {correct_irisX * 100 / (len(train_loaded))} | \"\n",
    "        f\"irisY: {correct_irisY * 100 / (len(train_loaded))} | \"\n",
    "        f\"irisR: {correct_irisR * 100 / (len(train_loaded))}\\n\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
